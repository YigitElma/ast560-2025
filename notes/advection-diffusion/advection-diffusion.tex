\documentclass[12pt]{article}

\usepackage{tikz}
\usetikzlibrary{decorations.markings}

%\usepackage{geometry}
%\geometry{paperwidth=170mm, paperheight=240mm, left=42pt, top=40pt, textwidth=280pt, marginparsep=20pt, marginparwidth=100pt, textheight=560pt, footskip=40pt}

%\documentclass[12pt]{amsart}
\usepackage[utf8]{inputenc}
\usepackage{times}
\usepackage{geometry}
\usepackage{tabularx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{color}
\usepackage{sidecap}
\usepackage{physics}
\usepackage{graphicx}
\usepackage{color}
\usepackage{verse}
\usepackage{hyperref}
\usepackage{tensor}
\usepackage{marginnote}
\usepackage{wrapfig}
\usepackage[font={small}]{caption}

\newcommand{\gke}{\texttt{Gkeyll}}

\newcommand{\attrib}[1]{
\nopagebreak{\raggedleft\footnotesize #1\par}\vskip0.1in}
\renewcommand{\poemtitlefont}{\normalfont\large\itshape\centering}

\newtheorem{proposition}{Proposition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{remark}{Remark}
\newtheorem{definition}{Definition}
\newtheorem{principle}{Principle}
\theoremstyle{definition}
\newtheorem{exmp}{Example}

\theoremstyle{definition}
\newtheorem{entry}{Entry}

\theoremstyle{definition}
\newtheorem{exer}{Exercise}

% auto-scaled figured
\newcommand{\incfig}{\centering\includegraphics}
\setkeys{Gin}{width=0.9\linewidth,keepaspectratio}

% Commonly used macros
\newcommand{\eqr}[1]{Eq.\thinspace(#1)}
\newcommand{\pfrac}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\pfracc}[2]{\frac{\partial^2 #1}{\partial #2^2}}
\newcommand{\pfraca}[1]{\frac{\partial}{\partial #1}}
\newcommand{\pfracb}[2]{\partial #1/\partial #2}
\newcommand{\pfracbb}[2]{\partial^2 #1/\partial #2^2}
\newcommand{\spfrac}[2]{{\partial_{#1}} {#2}}
\newcommand{\mvec}[1]{\mathbf{#1}}
\newcommand{\bmvec}[1]{\breve{\mathbf{#1}}}
\newcommand{\gvec}[1]{\boldsymbol{#1}}
\newcommand{\script}[1]{\mathpzc{#1}}
\newcommand{\gcn}{\nabla}
\newcommand{\gcs}{\nabla_{\mvec{x}}}
\newcommand{\gvs}{\nabla_{\mvec{v}}}

\newcommand{\resetall}{\setcounter{entry}{0}\setcounter{equation}{0}\setcounter{footnote}{0}}

\newcommand{\cbas}[1]{\gvec{\sigma}_{#1}}
\newcommand{\xbas}{\gvec{\sigma}_{1}}
\newcommand{\ybas}{\gvec{\sigma}_{2}}
\newcommand{\zbas}{\gvec{\sigma}_{3}}

\newcommand{\basis}[1]{\mvec{e}_{#1}}
\newcommand{\bbasis}[1]{\breve{\mvec{e}}_{#1}}
\newcommand{\dbasis}[1]{\mvec{e}^{#1}}
\newcommand{\bdbasis}[1]{\breve{\mvec{e}}^{#1}}

\newcommand{\nbasis}[1]{\hat{\mvec{e}}_{#1}}
\newcommand{\ndbasis}[1]{\hat{\mvec{e}}^{#1}}

\newcommand{\gbasis}[2]{\mvec{#1}_{#2}}
\newcommand{\gdbasis}[2]{\mvec{#1}^{#2}}

\newcommand{\veps}{\gvec{\varepsilon}}
\newcommand{\bdum}{\breve{\_}}
\newcommand{\vecspace}{\mathcal{V}}
\newcommand{\tvecspace}{T_pM}
\newcommand{\vnorm}[1]{\lVert{#1}\rVert}

\newcommand{\gsel}[2]{\langle{#1}\rangle_{#2}}
\newcommand{\gzsel}[1]{\langle {#1} \rangle}

\newcommand{\uln}[1]{\underline{#1}}

\newcommand{\dprod}{\mathfrak{D}}

\newcommand{\dvol}{\thinspace d^3\mvec{x}}
\newcommand{\dsurf}{\thinspace ds}

% Make the items smaller
\newcommand{\cramplist}{
	\setlength{\itemsep}{0in}
	\setlength{\partopsep}{0in}
	\setlength{\topsep}{0in}}
\newcommand{\cramp}{\setlength{\parskip}{.5\parskip}}
\newcommand{\zapspace}{\topsep=0pt\partopsep=0pt\itemsep=0pt\parskip=0pt}

%\marginpar{\raggedleft\footnotesize Margin note}

\title{AST560 2025: The Advection-Diffusion Equation}%
\author{Ammar H. Hakim}%
\date{\today}

\begin{document}
\maketitle

\tableofcontents

\section{Properties of the Advection-Diffusion Equation}

The advection-diffusion equation is a fundamental equation that
describes the transport of a scalar field, $f(\mvec{x},t)$ in a given
flow field. For scalar diffusion we can write this equation as
\begin{align}
  \pfrac{f}{t}
  +
  \gcn\cdot(\mvec{u} f)
  =
  \gcn\cdot(\alpha \gcn f).
  \label{eq:adv-diff}
\end{align}
Here $\mvec{u}(\mvec{x},t)$ is a \emph{given} time-dependent flow
field, and $\alpha(\mvec{x},t)$ is a \emph{given} time-dependent
diffusion coefficient. If we take the flow and diffusion as given,
this is a \emph{linear equation} for the scalar
$f(\mvec{x},t)$. Despite the apparent simplicity of this equation it
is fundamental to understanding the physics of mixing processes in
fluids and plasmas (which can be chaotic), and forms a good model and
a starting point for more complicated equations. For example, the
Vlasov-Maxwell equation and gyrokinetic equations are both
advection-diffusion equations in \emph{phase-space} and though
nonlinear, can be solved with schemes similar to those we will develop
for this linear equation.

Before we develop numerical methods to solve this equation we will
derive some important properties of the continuous system. There are
several reasons to do this analysis. First, it allows us to design
schemes that also mimic these properties in the discrete limit. Not
all continuous properties are inherited by the discrete scheme, and,
in fact, it may be possible that some properties may be \emph{harmful}
to mimic. Second, as we will see, a careful study of the proofs of the
continuous properties give us hints on how to construct proofs for the
discrete properties.


We will begin by deriving a \emph{weak-form} of
\eqr{\ref{eq:adv-diff}}. Let $w(\mvec{x},t)$ be a smooth
function\footnote{A smooth function is one that is continuous and has
  as many continuous derivatives as we need.}. Then, multiply
\eqr{\ref{eq:adv-diff}} by $w$ and integrate over an arbitrary volume
$\Omega$ to get
\begin{align}
  \int_\Omega w \pfrac{f}{t} \dvol
  +
  \oint_{\partial\Omega}
  w (\mvec{u} f - \alpha \gcn f)\cdot \mvec{n} \dsurf
  -
  \int_\Omega \gcn w \cdot (\mvec{u} f - \alpha \gcn f)  \dvol
  =
  0.
  \label{eq:adv-diff-weak}
\end{align}
\begin{wrapfigure}[12]{L}{0.25\textwidth}
\incfig{volelem.png} 
\caption{Arbitrary volume $\Omega$, with closed bounding surface
  $\partial\Omega$ and outward-pointing surface normal $\mvec{n}$.}
\label{fig:volume}
\end{wrapfigure}
In this expression $\partial\Omega$ is the surface bounding the volume
$\Omega$ and $\mvec{n}$ is the outward unit normal to
$\partial\Omega$. We have rearranged the terms and also used
integration by parts.

This weak-form, in a sense, is more general than the PDE
\eqr{\ref{eq:adv-diff}}: as the derivatives are no longer on the
solution variables, $f$ can be \emph{discontinuous}, and hence the
weak-form allows a broader class of solutions than the PDE. Later we
will use this weak-form to directly derive discrete schemes in the
\emph{discontinuous Galerkin} family of algorithms. For now, we will
use the weak-form to prove a couple of important properties of the
advection-diffusion equation.

\begin{proposition}
  The advection-diffusion equation conserves the total amount of
  scalar quantity. That is
  \begin{align}
    \frac{d}{dt} \int_\Omega f \dvol
    +
    \oint_{\partial\Omega}
    (\mvec{u} f - \alpha \gcn f)\cdot \mvec{n}
    \dsurf
    =
    0.
  \end{align}
\end{proposition}
\begin{proof}
  This proof is trivial: just set $w=1$ in the weak-form
  \eqr{\ref{eq:adv-diff-weak}}.
\end{proof}

This proof shows something that recurs in other conservation laws, and
so is important to understand. The proposition says that the amount of
``stuff'' in $\Omega$ is \emph{conserved}, that is, it can only change
due to the flow into and out of the volume $\Omega$ through its
surface $\partial\Omega$. The quantity $(\mvec{u} f - \alpha \gcn f)$
is called the \emph{flux}. All conservation laws have this structure:
some quantity an arbitrary volume can only change due to things
flowing in and out of that volume.

\begin{proposition}
  The advection-diffusion equation monotonically decays the $L_2$-norm
  of $f$ if the flow is incompressible, $\gcn\cdot\mvec{u} = 0$, and
  $\alpha > 0$. The $L_2$-norm is conserved if $\gcn\cdot\mvec{u} =
  0$ and $\alpha = 0$.
\end{proposition}
\begin{proof}
  Choose $w=f$ in the weak-form \eqr{\ref{eq:adv-diff-weak}} to get
\begin{align*}
  \frac{d}{dt}\int_\Omega \frac{1}{2}f^2 \dvol
  +
  \oint_{\partial\Omega}
  (\mvec{u} f^2 - \alpha \gcn \frac{1}{2} f^2)\cdot \mvec{n} \dsurf
  -
  \int_\Omega \gcn f \cdot (\mvec{u} f - \alpha \gcn f)  \dvol
  =
  0.
\end{align*}
Now, if $\gcn\cdot\mvec{u} = 0$ we can write $\gcn f \cdot \mvec{u} f$
as $\gcn\cdot(\mvec{u} f^2/2)$ to get
\begin{align*}
  \frac{d}{dt}\int_\Omega \frac{1}{2}f^2 \dvol
  +
  \oint_{\partial\Omega}
  (\mvec{u} f^2 - \alpha \gcn \frac{1}{2} f^2)\cdot \mvec{n} \dsurf
  -
  \int_\Omega \left(\gcn\cdot\frac{1}{2}\mvec{u} f^2 - \alpha 
  \| \gcn  f \|^2
  \right)  \dvol
  =
  0.
\end{align*}
Doing an integration by parts on the first volume term we finally get
\begin{align}
  \frac{d}{dt}\int_\Omega \frac{1}{2}f^2 \dvol
  +
  \oint_{\partial\Omega}
  (\mvec{u} \frac{1}{2} f^2 - \alpha \gcn \frac{1}{2} f^2)\cdot  \mvec{n} \dsurf
  =
  -
  \int_\Omega \alpha \| \gcn  f \|^2 \dvol.
\end{align}
If $\alpha > 0$ then this shows that the $L_2$-norm in $\Omega$ decays
monotonically, and remains conserved if $\alpha = 0$.
\end{proof}

Note that in this proof it was crucial that the flow is incompressible,
$\gcn\cdot\mvec{u} = 0$. Without this we can't show that the
$L_2$-norm decays. In fact, in a homework problem you will be asked to
construct a counter-example that explicitly shows that $L_2$-norm can
\emph{increase or decrease} for compressible flows.

The monotonic decay of the $L_2$-norm is an important property to
ensure in a discrete scheme. In fact, even when $\alpha=0$, we usually
have to ensure that the \emph{discrete scheme decays the $L_2$-norm},
even though the continuous equation conserves it. This is an example
in which the discrete scheme must \emph{not} mimic the continuous
properties as otherwise the numerical algorithm is no longer
\emph{stable}.



\begin{wrapfigure}[12]{L}{0.25\textwidth}
  \incfig{positive-cube.png} 
  \caption{A small, cubical volume with outflow from all sides. If
    $f_0>0$ then then $f$ can only decay towards zero, showing
    solution always remains positive if it is initially so.}
\end{wrapfigure}
We prove that solution remains positive if it is initially so. This is
probably the hardest property to ensure in a discrete scheme.
\begin{proposition}
  If the solution initially positive everywhere, then it remains so
  for all times. That is, if $f(\mvec{x},0) > 0$, then $f(\mvec{x},t)
  > 0$, for $t>0$.
\end{proposition}
\begin{proof}
  Consider a small, cubical volume with sides $L$ in which $f = f_0$
  initially. As an extreme case, let the flow be outward on each side
  and with magnitude $U$. We can ignore diffusion in this box. Then
  the weak-form shows that we must have
  \begin{align}
    \frac{df}{dt} = -\frac{6U}{L} f.
  \end{align}
  If $f_0$ and as $U>0$, we must have that $f \sim e^{-6U t/L }$. This
  means that $f$ in the box can only decay towards zero, but never
  become negative. Any other flow configuration will add $f$ to the
  box, hence independent of $\mvec{u}$ the solution will always remain
  positive.
\end{proof}

The properties above hold for \emph{arbitrary} volumes, and not just a
\emph{specific} volume. Such local properties are far more powerful
(and restrictive) than \emph{global} properties. For example, if we
were to extend the volume for density conservation to the whole
domain, then all one could say is that the total amount of $f$ in the
whole domain remains unchanged. However, this would not preclude $f$
disappearing at some point in the domain and instantaneously
reappearing somewhere else again. \emph{Local} conservation laws will
disallow this. As the volume is arbitrary, the only way $f$ can
decrease in this volume is by flux out of the surface.

\section{Steps Needed in Constructing a Solver}

Now that we have studied a few properties of the equation system we
wish to discretize we can switch to constructing the discrete
scheme. Notice that we have a \emph{time-dependent} equations with
first-order time-derivatives, and first and second order spatial
derivatives. Hence, we must
\begin{itemize}\cramplist
\item Choose a \emph{computational grid or mesh} that is appropriate
  for the problem we wish to solve. For now we will assume simple,
  rectangular domains and so will use a uniform, rectangular mesh.
\item Once we choose the mesh, we use a \emph{discrete approximation}
  to the spatial derivative terms that appear in the equation. For
  this, we need to carefully consider where on the mesh to compute the
  various quantities that appear in our equation, and from this
  construct a discrete derivative operator of sufficient accuracy. The
  discrete derivative operators will be different, for example, if we
  use a curvilinear mesh or a triangular mesh. We will consider such
  meshes later in the course.
\item We then need to decide how to advance the solution in time: we
  will replace the time derivative with a discrete approximation and
  \emph{advance} or \emph{march} the solution forward in time using a
  ODE solver. We will of course need to prescribed initial condition
  and apply the appropriate \emph{boundary conditions}.
\end{itemize}

Each of these steps, mesh generation, constructing spatial discrete
operators, and choosing a time-stepper are complicated and impact the
quality of the numerical solution we will obtain. Once we have made
all these choices we can use the \emph{discrete} scheme to prove
various properties. Not all properties of the continuous equations are
inherited by the discrete scheme. Depending on the set of problems we
wish to study, we may want to ensure some key properties of the
continuous scheme are inherited by the discrete scheme.

In general, we will also find that there is a tradeoff between
accuracy of the scheme and \emph{robustness}. For example, a highly
accurate scheme could violate positivity, or will develop spurious
high-$k$ modes when the spatial scales of the solution approach the
grid spacing. In general, some form of \emph{regularization}, for
example, \emph{limiters} or extra diffusion, may be needed to obtain a
stable and useful solver.

Of course, implementing the scheme in computer code, specially to
create a production solver is highly non-trivial: one needs to have
good programming skills and follow good software engineering
discipline. The appearance of modern parallel processors and GPUs has
made the process even more complicated as, in general, one needs to
have a deep understanding of the underlying hardware to obtain best
performance from the solver.

Finally, I remark that production solvers applied to ``real'' physics
or engineering problems will invariably encounter issue that will not
show up in simple test cases. In fact, if anything \emph{can} go
wrong, it \emph{will} go wrong. Eventually. Hence, it is important to
have a deep understanding of \emph{both} the physics of the equations
\emph{and} the properties of the discrete system. It is seldom
fruitful or productive to treat a numerical method as a black-box. The
deeper one understand the numerics, the better one can be confident in
obtaining useful results from them.

\section{Constructing Finite-Difference Formulas}

In the advection-diffusion equation we have first-order and
second-order derivative operators. We will use
\emph{finite-differences} to compute these, however, accounting for
some form of \emph{upwinding} for the advection term that we explain
below.

Finite-difference (FD) approximations can be systematically
constructed by constructing \emph{interpolating polynomials} given
values of a function at a set of discrete point. The key approach here
is to construct an \emph{interpolating} polynomial in the following
way. Let $x_i$, $i=1,\ldots,N$ be a set of locations on a 1D grid and
$f = f(x_i)$ the corresponding values of $f$ at those points. The
first step in constructing FD scheme is to use these to construct a
continuous polynomial $f_h(x)$ that satisfies the property that
\begin{align}
  f_h(x_i) = f_i
\end{align}
for $i=1,\ldots,N$. One way to determine this polynomial is to assume
a form
\begin{align}
  f_h(x) = a_0 + a_1 x + \ldots + a_{N-1} x^{N-1}
\end{align}
where $a_j$, $j = 0, \ldots, N-1$ are $N$ coefficients. The condition
$f_h(x_i) = f_i$ will give us $N$ linear equations to determine the
$N$ unknowns $a_j$, hence determining the polynomial $f_h(x)$.

In reality we do not actually need to construct or solve any linear
system. Instead, we can use \emph{Lagrange interpolating} polynomials
to construct $f_h(x)$ directly. To illustrate, let $N=3$. Then the
interpolating polynomial is simply
\begin{align}
  f_h(x)
  =
  \frac{(x-x_2)(x-x_3)}{(x_1-x_2)(x_1-x_3)} f_1 
  +
  \frac{(x-x_1)(x-x_3)}{(x_2-x_1)(x_2-x_3)} f_2
  +
  \frac{(x-x_1)(x-x_2)}{(x_3-x_1)(x_3-x_2)} f_3.
\end{align}
Note the construction of this polynomial: when $x=x_1$, for example,
the second and third terms vanish, and we get $f_h(x_1) = f_1$, as
required. Hence, this quadratic polynomial is the interpolation
polynomial we are seeking. Of course, the generalization to more
points is obvious.

\begin{figure}
  \setkeys{Gin}{width=0.45\linewidth,keepaspectratio}
  \incfig{a560-patho-interp.pdf} 
  \incfig{a560-patho-cheb.pdf}
  \caption{Left: Interpolation of a smooth function on uniformly
    spaced set of nodes. Black line is the interpolation polynomial
    that shows severe oscillations, despite the function (red line)
    being smooth. Right: The same, except using Chebyshev
    interpolation points. Using these significantly improves the
    quality of the interpolation.}
  \label{fig:patho-fits}
\end{figure}

Interpolation on uniformly spaced points can often give highly
inaccurate results. For example, consider the function
\begin{align}
  f(x) = \frac{1}{1+ 10 x^2}
\end{align}
on $x \in [-1,1]$, This function is smooth but when an interpolating
polynomial is constructed using uniformly spaced points it behaves in
a pathological manner. One way around this ``ringing'' is to use a
\emph{non-uniformly} spaced sets of points, for example, Legendre or
Chebyshev points. See Fig.\thinspace\ref{fig:patho-fits}.

Once we have the interpolation polynomial we can use it to approximate
the values and derivatives we need at various places in the
algorithm. For example, at some arbitrary point $x$ we can approximate
$f(x) = f_h(x)$, or
\begin{align}
  \frac{df(x)}{dx} \approx \frac{df_h(x)}{dx}.
\end{align}
Evaluation of the interpolation polynomial and its derivative is often
made much easier by use of a compute algebra system (CAS). I highly
recommend you use some CAS like Maple, Mathematica, or (my personal
choice) Maxima. The use a CAS greatly simplified the various algebraic
manipulations needed and also reduces the possibility of errors.

\begin{wrapfigure}[14]{L}{0.4\textwidth}
\incfig{three-point-stencil.png} 
\caption{Three cells of a uniform 1D grid. The red curve is a
  quadratic that fits the cell-center values $f_{L}$, $f_0$ and $f_R$
  and is used to construct finite-difference schemes.}
\label{fig:three-point-stencil}
\end{wrapfigure}

As example, consider we have three cells in a uniform, 1D grid with
cell spacing $\Delta x$. We will choose to locate the $f$ at
\emph{cell-centers}. Then we can use the interpolation formula above
to construct a polynomial $f_h(x)$ in the middle cell,
$-\Delta x/2 \le x \le \Delta x/2$, assuming, without loss of
generality, that $x_0 = 0$. Then, for example, we can compute as
approximation to the second derivative at the point $x_0 = 0$ by
computing $d^2 f_h/d x^2$ and evaluating the result at $x=0$. We get
the expected central difference formulas
\begin{align}
  \frac{\partial f_h}{\partial x}
  &=
  \frac{f_R - f_L}{2 \Delta x} \\
  \frac{\partial ^2f_h}{\partial x^2}
  &=
  \frac{f_R - 2 f_0 + f_L}{\Delta x^2}.
\end{align}
This, of course, should not be surprising to you but illustrates the
general procedure for computing approximations from the interpolating
polynomials.

As we will see below, we will also need to compute the values $f_R$
and $f_L$ marked in
Fig.\thinspace\ref{fig:three-point-stencil}. Again, we simply
evaluate the Lagrange interpolating polynomial at $x = \pm \Delta x/2$
to get
\begin{subequations}\label{eq:fedge-vals}
\begin{align}
  f^+ &= \frac{1}{8} ( 3 f_{R} + 6 f_0 - f_L ) \\
  f^- &= \frac{1}{8} ( 3 f_{L} + 6 f_0 - f_R ).
\end{align}
\end{subequations}

For a smooth $f(x)$ the accuracy of the interpolating polynomial at
some point $x$ will depend on the size of the \emph{stencil}, that is,
the number of points (cell-centers in this case) that are used in
constructing it. To determine the accuracy and convergence of the
interpolating polynomial we use a Taylor expansion of $f(x)$ around
$x = 0$:
\begin{align}
  f(x) = \sum_{n=0} f^{(n)} \frac{x^n}{n!} \label{eq:taylor-f}
\end{align}
where $f^{(n)}$ is the $n$-th derivative of $f(x)$ evaluated at
$x=0$. We can now use this expansion in the finite-difference
expressions and compare with the exact derivatives. For example we can
compute
\begin{align}
  f_R 
  &= f(\Delta x) 
  = f_0 + \Delta x f^{(1)} + \frac{\Delta x^2}{2} f^{(2)}  
  + \frac{\Delta x^3}{6} f^{(3)}  + \ldots \\
  f_L
  &= f(-\Delta x) 
  = f_0 - \Delta x f^{(1)} + \frac{\Delta x^2}{2} f^{(2)}  
  - \frac{\Delta x^3}{6} f^{(3)}  + \ldots.
\end{align}
Using this in the finite-difference formula for the first derivative
we get
\begin{align}
  \frac{\partial f_h}{\partial x}
  =
  \frac{f_R - f_L}{2 \Delta x}
  =
  f^{(1)}
  +
  \frac{\Delta x^2}{6} f^{(3)} + \ldots
\end{align}
This shows that with the $3$-point stencil, the first derivative
computed using the finite-difference formula is \emph{second-order
  accurate}. In the same way we can compute
\begin{align}
  \frac{\partial^2 f_h}{\partial x^2}
  =
  \frac{f_R - 2 f_0 + f_L}{\Delta x^2}
  =
  f^{(2)}
  +
  \frac{\Delta x^2}{12} f^{(4)} + \ldots
\end{align}
again showing that the second derivative is also \emph{second-order
  accurate}.

We can also compute the accuracy of the finite-difference formulas for
computing the edge values $f^{\pm}$. Using the Taylor expansions in
\eqr{\ref{eq:fedge-vals}} we get
\begin{align}
  f^{\pm} - f(\pm \Delta x/2)
  = \pm \frac{\Delta x^3}{16} f^{(3)} + \ldots
\end{align}
showing that the edge values are computed to \emph{third-order}
accuracy.

The validity of the above Taylor series analysis, of course, depends
crucially on the fact that the solution $f(x)$ is sufficiently smooth
that the needed derivatives exist. This may not always be true, for
example, in the presence of shocks or sharp gradients in the
solution. It is also clear that the degree of smoothness we need will
depend on the stencil size (and the order of the derivative we are
computing): hence, wider stencils (more accurate derivatives) will be
increasingly \emph{less} robust, with potentially large errors in
regions of sharp gradients. In general, this means that unless great
care is taken, high order methods (third or higher order) are far
\emph{less robust} than lower order methods (second-order). This is one
of the key reasons that many commercial computational physics
packages, especially for fluid mechanics\footnote{Solid mechanics and
  heat transfer problems can be solved with higher order methods, as
  the solutions are typically much smoother that fluid problems. In
  the latter, specially in invicid or low viscosity fluids, the flow
  tends to cascade to shorter wavelengths (high-$k$) modes.},
typically use low-order schemes, sometimes even effectively just
first-order schemes.

\begin{figure}
  \setkeys{Gin}{width=0.45\linewidth,keepaspectratio}
  \incfig{a560-kbar-diff1.pdf} 
  \incfig{a560-kbar-diff2.pdf} 
  \caption{Left: Numerical dispersion relation (blue) plotted as a
    function of wave-number for central difference scheme for the
    constant advection. Significant dispersion and aliasing of modes
    is seen. Right: Damping of wave-number $k$ for the
    constant-coefficient diffusion equation. High-$k$ modes are
    \emph{under-damped}. Red curves are the exact dispersion
    relations.}
  \label{fig:num-disp}
\end{figure}


Besides Taylor series analysis, we can also do a Fourier analysis to
understand how a single mode is represented by the finite-difference
formula for the derivative operators. To do this we will take a single
Fourier mode
\begin{align}
  f(x) = e^{ikx}
\end{align}
and substitute this in the finite-difference formula. For, example,
consider the linear advection equation
\begin{align}
  \pfrac{f}{t} + u \pfrac{f}{x} = 0.
\end{align}
with its semi-discrete form
\begin{align}
  \pfrac{f_h}{t} + u \frac{f_R - f_L}{2 \Delta x} = 0.
\end{align}
Using the Fourier expansion $f_h(x) = e^{-i\omega t} e^{ikx}$ we get
\begin{align}
  -i\omega + u \frac{e^{ik \Delta x } - e^{-ik \Delta x } }{2 \Delta x} = 0
\end{align}
This gives a numerical dispersion relation
\begin{align}
  \omega \Delta x  =  u \bar{k} \Delta x = u \sin(k\Delta x).
\end{align}
Hence, the discrete scheme ``sees'' a \emph{modified wave-number}
$\bar{k}$ rather than the exact wave-number $k$. In general, the
modified wave-number will have both a real and an imaginary
part. However, due to the symmetry of the central-difference formula,
$\bar{k}$ only has a real-part. The left panel of
Fig.\thinspace\ref{fig:num-disp} compares the numerical dispersion
with the exact dispersion.  Notice there is strong deviation from the
exact dispersion for even modest waves numbers. This figure also shows
strong \emph{aliasing} of modes: each long wavelength mode is
\emph{aliased} to a corresponding short wavelength mode. Further, this
figure also shows that if we were to use the central-difference
formula for advection, modes with different wave-numbers would
propagate with different phase- and group velocities, causing
\emph{dispersion} of waves.

Now consider a constant-coefficient diffusion equation
\begin{align}
  \pfrac{f}{t} = \alpha \pfracc{f}{x}
\end{align}
with its semi-discrete form
\begin{align}
  \pfrac{f_h}{t} = \alpha \frac{f_R - 2 f_0 + f_L}{\Delta x^2}.
\end{align}
In a similar manner as above we can do a Fourier analysis assuming a
central-difference formula for the second derivative. Again using
$f_h(x) = e^{-i\omega t} e^{ikx}$ we will get the dispersion relation
\begin{align}
  -i\omega
  =
  \alpha \frac{e^{ik \Delta x } - 2 + e^{-ik \Delta x } }{\Delta x^2}.
\end{align}
This dispersion relation shows that a mode with wave-number $k$ will
be damped as $e^{-\alpha \bar{k}^2 t}$ where
\begin{align}
  \bar{k}^2\Delta x^2 = 2 - 2 \cos(k \Delta x).
\end{align}
Recall that the actual damping should be $e^{-\alpha k^2} t$. Hence,
as we see in the right-panel of Fig.\thinspace\ref{fig:num-disp} the
high-$k$ modes will be \emph{under-damped} by this central difference
scheme.

\end{document}


